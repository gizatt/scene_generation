{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pydrake\n",
    "import torch\n",
    "import pyro\n",
    "from pyro import poutine\n",
    "import time\n",
    "\n",
    "import scene_generation.data.dataset_utils as dataset_utils\n",
    "from scene_generation.models.planar_multi_object_multi_class_2 import MultiObjectMultiClassModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2d_box : \n",
      "(2479, 5)\n",
      "means:  [ 0.05841386  0.19564861 -0.0062935   0.20078573  0.2000771 ]\n",
      "vars:  [0.48295732 0.1329204  1.05602027 0.05787565 0.05763485]\n",
      "2d_sphere : \n",
      "(2472, 4)\n",
      "means:  [ 0.04950154  0.18883129 -0.19078293  0.09987665]\n",
      "vars:  [0.50612466 0.13069154 2.06112832 0.02919288]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#DATA_FILE = \"/home/gizatt/projects/scene_generation/data/planar_bin/planar_bin_static_scenes_geometric.yaml\"\n",
    "DATA_FILE = \"/home/gizatt/projects/scene_generation/data/planar_bin/planar_bin_static_scenes.yaml\"\n",
    "scenes_dataset_yaml = dataset_utils.ScenesDataset(DATA_FILE)\n",
    "params_by_object_class = {}\n",
    "for env_i in range(len(scenes_dataset_yaml)):\n",
    "    env = scenes_dataset_yaml[env_i]\n",
    "    for obj_i in range(env[\"n_objects\"]):\n",
    "        obj_yaml = env[\"obj_%04d\" % obj_i]\n",
    "        class_name = obj_yaml[\"class\"]\n",
    "        if class_name not in params_by_object_class.keys():\n",
    "            params_by_object_class[class_name] = []\n",
    "        params_by_object_class[class_name].append(obj_yaml[\"pose\"] + obj_yaml[\"params\"])\n",
    "\n",
    "for object_name in params_by_object_class.keys():\n",
    "    print object_name, \": \"\n",
    "    params = np.stack(params_by_object_class[object_name])\n",
    "    print params.shape\n",
    "    print \"means: \", np.mean(params, axis=0)\n",
    "    print \"vars: \", np.std(params, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes_dataset = dataset_utils.ScenesDatasetVectorized(DATA_FILE)\n",
    "data = scenes_dataset.get_full_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All params:  ['keep_going_weights', 'context_updater_module$$$weight_hh_l0', 'new_class_weights', 'context_updater_module$$$bias_hh_l0', 'class_encoder_module_1$$$4.bias', 'params_vars_1', 'params_vars_0', 'context_updater_module$$$weight_ih_l0', 'class_encoder_module_0$$$2.weight', 'class_encoder_module_1$$$4.weight', 'class_encoder_module_0$$$4.weight', 'context_updater_module$$$bias_ih_l0', 'class_encoder_module_0$$$0.weight', 'class_encoder_module_0$$$4.bias', 'class_encoder_module_0$$$0.bias', 'class_encoder_module_1$$$0.weight', 'class_encoder_module_1$$$2.weight', 'params_means_0', 'params_means_1', 'class_encoder_module_1$$$2.bias', 'class_encoder_module_0$$$2.bias', 'class_encoder_module_1$$$0.bias']\n",
      ". \n",
      "\n",
      "keep_going_weights :  [0.5249792 0.5249792 0.5249792 0.5249792 0.5249792 0.5249792 0.5249792\n",
      " 0.5249792 0.5249792 0.5249792 0.4750208 0.4750208 0.4750208 0.4750208\n",
      " 0.4750208 0.4750208 0.4750208 0.4750208 0.4750208]\n",
      "new_class_weights :  [0.54983395 0.450166  ]\n",
      "params_means_0 :  [ 0.1         0.10000001 -0.1         0.10000001  0.10000001]\n",
      "params_means_1 :  [ 0.10000001  0.10000001 -0.1         0.1       ]\n",
      "params_vars_0 :  [0.9048374 0.9048374 1.105171  0.9048374 0.9048374]\n",
      "params_vars_1 :  [0.9048374 0.9048374 1.105171  0.9048374]\n",
      ". . . . . \n",
      "\n",
      "keep_going_weights :  [0.9531636  0.9270811  0.88282907 0.83604527 0.7911249  0.73064727\n",
      " 0.69337785 0.62772655 0.5817533  0.52790904 0.4739529  0.4182467\n",
      " 0.36811337 0.3086358  0.25123492 0.19502239 0.14296119 0.09320614\n",
      " 0.06330024]\n",
      "new_class_weights :  [0.50065255 0.49934742]\n",
      "params_means_0 :  [ 0.05813773  0.19541991 -0.00616166  0.20356068  0.2028969 ]\n",
      "params_means_1 :  [ 0.04962771  0.18876146 -0.18983419  0.10444192]\n",
      "params_vars_0 :  [0.48374543 0.13172261 1.0560724  0.05898624 0.05874188]\n",
      "params_vars_1 :  [0.5071542  0.12953769 2.0667918  0.0296611 ]\n",
      ". . . . . \n",
      "\n",
      "keep_going_weights :  [0.98248994 0.9396886  0.88200104 0.83599627 0.79199773 0.7299967\n",
      " 0.69399875 0.6279986  0.58200085 0.5279996  0.4739995  0.41799918\n",
      " 0.36799997 0.3080019  0.2519978  0.1939966  0.14400041 0.08999251\n",
      " 0.04400239]\n",
      "new_class_weights :  [0.50070786 0.4992921 ]\n",
      "params_means_0 :  [ 0.06002746  0.20098495 -0.00629245  0.20486854  0.20790273]\n",
      "params_means_1 :  [ 0.05243189  0.1837525  -0.19077994  0.09941447]\n",
      "params_vars_0 :  [0.4829845  0.13260731 1.0560217  0.0578958  0.05834677]\n",
      "params_vars_1 :  [0.50606054 0.13197982 2.0611055  0.02954819]\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Rig for SVI, running with AutoDelta, which converges fairly reliably but\n",
    "# confuses the variances\n",
    "from collections import defaultdict\n",
    "from torch.distributions import constraints\n",
    "from pyro.infer import Trace_ELBO, SVI\n",
    "from pyro.contrib.autoguide import AutoDelta, AutoDiagonalNormal, AutoMultivariateNormal, AutoGuideList\n",
    "import datetime\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "log_dir = \"/home/gizatt/projects/scene_generation/models/runs/pmomc2/\" + datetime.datetime.now().strftime(\n",
    "    \"%Y-%m-%d-%H-%m-%s\")\n",
    "writer = SummaryWriter(log_dir)\n",
    "def write_np_array(writer, name, x, i):\n",
    "    for yi, y in enumerate(x):\n",
    "        writer.add_scalar(name + \"/%d\" % yi, y, i)\n",
    "        \n",
    "print \"All params: \", pyro.get_param_store().get_all_param_names()\n",
    "interesting_params = [\"keep_going_weights\",\n",
    "                      \"new_class_weights\",\n",
    "                      \"params_means_0\", \"params_means_1\",\n",
    "                      \"params_vars_0\", \"params_vars_1\"]\n",
    "    \n",
    "model = MultiObjectMultiClassModel(scenes_dataset)\n",
    "pyro.clear_param_store()\n",
    "guide = AutoDelta(poutine.block(model.model, hide=[\"obs\"]))\n",
    "\n",
    "optim = pyro.optim.Adam({'lr': 0.1, 'betas': [0.8, 0.99]})\n",
    "elbo = Trace_ELBO(max_plate_nesting=1)\n",
    "svi = SVI(model.model, guide, optim, loss=elbo)\n",
    "losses = []\n",
    "        \n",
    "snapshots = {}\n",
    "for i in range(101):\n",
    "    # Guesses on important things:\n",
    "    # Big subsamples appear really important -- I had major loss of\n",
    "    # convergence when using smaller subsample sizes (like ~50).\n",
    "    # Also important: prior on the variance must be REALLY low.\n",
    "    # Otherwise long_box_mean diverges to negative... :(\n",
    "    # I think there's a fundamental problem with variance estimation\n",
    "    # under this guide / with this system -- see the single-box-dataset\n",
    "    # estimates that don't capture the x vs y variance.\n",
    "    loss = svi.step(data, subsample_size=250)\n",
    "    losses.append(loss)\n",
    "    writer.add_scalar('loss', loss, i)\n",
    "\n",
    "    for p in pyro.get_param_store().keys():\n",
    "        if p not in snapshots.keys():\n",
    "            snapshots[p] = []\n",
    "        snapshots[p].append(pyro.param(p).cpu().detach().numpy().copy())\n",
    "    for p in interesting_params:\n",
    "        write_np_array(writer, p, snapshots[p][-1], i)\n",
    "    if (i % 10 == 0):\n",
    "        print \".\",\n",
    "    if (i % 50 == 0):\n",
    "        print \"\\n\"\n",
    "        for p in interesting_params:\n",
    "            print p, \": \", pyro.param(p).detach().numpy()\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'obj_0002': {'color': [0.6200758153988021, 1.0, 1.0, 0.5], 'pose': [0.27748194336891174, 0.26269716024398804, -0.7031012177467346], 'params': [0.1910230815410614, 0.25044190883636475], 'class': '2d_box', 'params_names': ['height', 'length']}, 'obj_0003': {'color': [0.7809528565765493, 1.0, 1.0, 0.5], 'pose': [0.2374354898929596, 0.16561977565288544, -4.372330665588379], 'params': [0.11553522944450378], 'class': '2d_sphere', 'params_names': ['radius']}, 'obj_0000': {'color': [0.6349652299591473, 1.0, 1.0, 0.5], 'pose': [-0.403425931930542, 0.08972030133008957, -3.092280864715576], 'params': [0.12652935087680817], 'class': '2d_sphere', 'params_names': ['radius']}, 'obj_0001': {'color': [0.6801744155299632, 1.0, 1.0, 0.5], 'pose': [0.4625639319419861, 0.4472746253013611, -0.5235490202903748], 'params': [0.26720577478408813, 0.21856629848480225], 'class': '2d_box', 'params_names': ['height', 'length']}, 'obj_0006': {'color': [0.6295699069295791, 1.0, 1.0, 0.5], 'pose': [0.9539144039154053, 0.23903506994247437, 2.0808796882629395], 'params': [0.11081165820360184], 'class': '2d_sphere', 'params_names': ['radius']}, 'obj_0007': {'color': [0.7473732187966622, 1.0, 1.0, 0.5], 'pose': [0.3576184809207916, 0.19195692241191864, -1.14006507396698], 'params': [0.17950847744941711, 0.20093193650245667], 'class': '2d_box', 'params_names': ['height', 'length']}, 'obj_0004': {'color': [0.740078605561449, 1.0, 1.0, 0.5], 'pose': [0.4972076416015625, 0.2248287945985794, -1.8290109634399414], 'params': [0.09222576767206192], 'class': '2d_sphere', 'params_names': ['radius']}, 'obj_0005': {'color': [0.6136839016439264, 1.0, 1.0, 0.5], 'pose': [-0.6572299003601074, 0.25044021010398865, -0.2136348932981491], 'params': [0.06550849229097366], 'class': '2d_sphere', 'params_names': ['radius']}, 'obj_0008': {'color': [0.6760663826509263, 1.0, 1.0, 0.5], 'pose': [-0.5419890284538269, 0.2599707841873169, -2.4945247173309326], 'params': [0.1140577644109726], 'class': '2d_sphere', 'params_names': ['radius']}, 'obj_0009': {'color': [0.6505905472546353, 1.0, 1.0, 0.5], 'pose': [-0.4578985571861267, 0.3649207055568695, -4.258161544799805], 'params': [0.09856492280960083], 'class': '2d_sphere', 'params_names': ['radius']}, 'n_objects': 9}\n",
      "Connecting to meshcat-server at zmq_url=tcp://127.0.0.1:6000...\n",
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7000/static/\n",
      "Connected to meshcat-server.\n"
     ]
    }
   ],
   "source": [
    "# Convert that data back to a YAML environment, which is easier to\n",
    "# handle.\n",
    "scene_with_most_objects = None\n",
    "for k in range(1):\n",
    "    generated_data, generated_encodings, generated_contexts = model.model()\n",
    "    scene_yaml = scenes_dataset.convert_vectorized_environment_to_yaml(\n",
    "        generated_data)\n",
    "    if scene_with_most_objects is None or scene_yaml[0][\"n_objects\"] > scene_with_most_objects[\"n_objects\"]:\n",
    "        scene_with_most_objects = scene_yaml[0]\n",
    "        \n",
    "print scene_with_most_objects\n",
    "dataset_utils.DrawYamlEnvironment(scene_with_most_objects, \"planar_bin\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py27_pyro)",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
