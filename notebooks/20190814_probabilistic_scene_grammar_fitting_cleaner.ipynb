{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from copy import deepcopy\n",
    "import datetime\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import yaml\n",
    "\n",
    "import pydrake  # MUST BE BEFORE TORCH OR PYRO\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "import torch.multiprocessing as mp\n",
    "from tensorboardX import SummaryWriter\n",
    "from torchviz import make_dot\n",
    "\n",
    "import scene_generation.data.dataset_utils as dataset_utils\n",
    "from scene_generation.models.probabilistic_scene_grammar_nodes import *\n",
    "from scene_generation.models.probabilistic_scene_grammar_model import *\n",
    "from scene_generation.models.probabilistic_scene_grammar_fitting import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = int(time.time()) % (2**32-1)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "pyro.enable_validation(True)\n",
    "pyro.clear_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_writer = True\n",
    "\n",
    "hyper_parse_tree = generate_hyperexpanded_parse_tree()\n",
    "#plt.figure().set_size_inches(20, 20)\n",
    "#draw_parse_tree(hyper_parse_tree, label_name=True, label_score=False)\n",
    "#plt.show()\n",
    "\n",
    "train_dataset = dataset_utils.ScenesDataset(\"../data/table_setting/table_setting_environments_simple_train\")\n",
    "test_dataset = dataset_utils.ScenesDataset(\"../data/table_setting/table_setting_environments_simple_test\")\n",
    "print(\"%d training examples\" % len(train_dataset))\n",
    "print(\"%d test examples\" % len(test_dataset))\n",
    "\n",
    "\n",
    "log_dir = \"/home/gizatt/projects/scene_generation/models/runs/psg/table_setting/\" + datetime.datetime.now().strftime(\n",
    "    \"%Y-%m-%d-%H-%m-%s\")\n",
    "\n",
    "if use_writer:\n",
    "    writer = SummaryWriter(log_dir)\n",
    "    def write_np_array(writer, name, x, i):\n",
    "        for yi, y in enumerate(x):\n",
    "            writer.add_scalar(name + \"/%d\" % yi, y, i)\n",
    "\n",
    "\n",
    "param_val_history = []\n",
    "score_history = []\n",
    "score_test_history = []\n",
    "\n",
    "# Initialize the guide GVS as mean field\n",
    "guide_gvs = hyper_parse_tree.get_global_variable_store()\n",
    "# Note -- if any terminal nodes have global variables associated with\n",
    "# them, they won't be in the guide.\n",
    "for var_name in guide_gvs.keys():\n",
    "    guide_gvs[var_name][0] = pyro.param(var_name + \"_est\",\n",
    "                                        guide_gvs[var_name][0],\n",
    "                                        constraint=guide_gvs[var_name][1].support)\n",
    "# do gradient steps\n",
    "print_param_store()\n",
    "best_loss_yet = np.infty\n",
    "\n",
    "# setup the optimizer\n",
    "adam_params = {\"lr\": 0.001, \"betas\": (0.8, 0.95)}\n",
    "all_params_to_optimize = set(pyro.get_param_store()._params[name] for name in pyro.get_param_store().keys())\n",
    "# Ensure everything in pyro param store has zero grads\n",
    "for p in all_params_to_optimize:\n",
    "    assert(p.requires_grad == True)\n",
    "    p.grad = torch.zeros(p.shape)\n",
    "    p.share_memory_()\n",
    "    p.grad.share_memory_()\n",
    "\n",
    "def per_param_callable(module_name, param_name):\n",
    "    if \"var\" in param_name or \"weights\" in param_name:\n",
    "        return {\"lr\": 0.1, \"betas\": (0.8, 0.95)}\n",
    "\n",
    "    else:\n",
    "        return {\"lr\": 0.001, \"betas\": (0.8, 0.95)}\n",
    "optimizer = Adam(per_param_callable)\n",
    "baseline = 0.\n",
    "baseline = 0.\n",
    "\n",
    "\n",
    "snapshots = {}\n",
    "\n",
    "for step in range(500):\n",
    "    # Synchronize gvs and param store. In the case of constrained parameters,\n",
    "    # the constrained value returned by pyro.param() is distinct from the\n",
    "    # unconstrianed value we optimize, so we need to regenerate the constrained value.\n",
    "    for var_name in guide_gvs.keys():\n",
    "        guide_gvs[var_name][0] = pyro.param(var_name + \"_est\")\n",
    "\n",
    "    loss = calc_score_and_backprob_async(train_dataset, n=10, guide_gvs=guide_gvs, optimizer=optimizer)\n",
    "    #loss = svi.step(observed_tree)\n",
    "    score_history.append(loss)\n",
    "\n",
    "    if (step % 10 == 0):\n",
    "        # Evaluate on a few test data points\n",
    "        loss_test = calc_score_and_backprob_async(test_dataset, n=5, guide_gvs=guide_gvs)\n",
    "        score_test_history.append(loss_test)\n",
    "        print(\"Loss_test: \", loss_test)\n",
    "\n",
    "        if loss_test < best_loss_yet:\n",
    "            best_loss_yet = loss\n",
    "            pyro.get_param_store().save(\"best_on_test_save.pyro\")\n",
    "\n",
    "        # Also generate a few example environments\n",
    "        # Generate a ground truth test environment\n",
    "        plt.figure().set_size_inches(20, 20)\n",
    "        for k in range(4):\n",
    "            plt.subplot(2, 2, k+1)\n",
    "            parse_tree = generate_unconditioned_parse_tree(initial_gvs=guide_gvs)\n",
    "            yaml_env = convert_tree_to_yaml_env(parse_tree)\n",
    "            try:\n",
    "                DrawYamlEnvironmentPlanar(yaml_env, base_environment_type=\"table_setting\", ax=plt.gca())\n",
    "            except:\n",
    "                print(\"Unhandled exception in drawing yaml env\")\n",
    "            draw_parse_tree(parse_tree, label_name=True, label_score=True)\n",
    "        if use_writer:\n",
    "            writer.add_scalar('loss_test', loss_test.item(), step)\n",
    "            writer.add_figure(\"generated_envs\", plt.gcf(), step, close=True)\n",
    "\n",
    "    all_param_state = {name: pyro.param(name).detach().cpu().numpy().copy() for name in pyro.get_param_store().keys()}\n",
    "    if use_writer:\n",
    "        writer.add_scalar('loss', loss.item(), step)\n",
    "        for param_name in all_param_state.keys():\n",
    "            write_np_array(writer, param_name, all_param_state[param_name], step)\n",
    "    param_val_history.append(all_param_state)\n",
    "    #print(\"active param names: \", active_param_names)\n",
    "    print(\"Place setting plate mean est: \", pyro.param(\"place_setting_plate_mean_est\"))\n",
    "    print(\"Place setting plate var est: \", pyro.param(\"place_setting_plate_var_est\"))\n",
    "print(\"Final loss: \", loss)\n",
    "print_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_writer = True\n",
    "\n",
    "hyper_parse_tree = generate_hyperexpanded_parse_tree()\n",
    "#plt.figure().set_size_inches(20, 20)\n",
    "#draw_parse_tree(hyper_parse_tree, label_name=True, label_score=False)\n",
    "#plt.show()\n",
    "\n",
    "train_dataset = dataset_utils.ScenesDataset(\"../data/table_setting/table_setting_environments_simple_train\")\n",
    "test_dataset = dataset_utils.ScenesDataset(\"../data/table_setting/table_setting_environments_simple_test\")\n",
    "print(\"%d training examples\" % len(train_dataset))\n",
    "print(\"%d test examples\" % len(test_dataset))\n",
    "\n",
    "\n",
    "log_dir = \"/home/gizatt/projects/scene_generation/models/runs/psg/table_setting/\" + datetime.datetime.now().strftime(\n",
    "    \"%Y-%m-%d-%H-%m-%s\")\n",
    "\n",
    "if use_writer:\n",
    "    writer = SummaryWriter(log_dir)\n",
    "    def write_np_array(writer, name, x, i):\n",
    "        for yi, y in enumerate(x):\n",
    "            writer.add_scalar(name + \"/%d\" % yi, y, i)\n",
    "\n",
    "env = train_dataset[1]\n",
    "\n",
    "score_history = []\n",
    "\n",
    "# Initialize the guide GVS as mean field\n",
    "guide_gvs = hyper_parse_tree.get_global_variable_store()\n",
    "# Note -- if any terminal nodes have global variables associated with\n",
    "# them, they won't be in the guide.\n",
    "for var_name in guide_gvs.keys():\n",
    "    guide_gvs[var_name][0] = pyro.param(var_name + \"_est\",\n",
    "                                        guide_gvs[var_name][0],\n",
    "                                        constraint=guide_gvs[var_name][1].support)\n",
    "# do gradient steps\n",
    "print_param_store()\n",
    "best_loss_yet = np.infty\n",
    "\n",
    "# setup the optimizer\n",
    "all_params_to_optimize = set(pyro.get_param_store()._params[name] for name in pyro.get_param_store().keys())\n",
    "# Ensure everything in pyro param store has zero grads\n",
    "for p in all_params_to_optimize:\n",
    "    assert(p.requires_grad == True)\n",
    "    p.grad = torch.zeros(p.shape)\n",
    "    p.share_memory_()\n",
    "    p.grad.share_memory_()\n",
    "\n",
    "def per_param_callable(module_name, param_name):\n",
    "    if \"var\" in param_name:\n",
    "        return {\"lr\": 0.1, \"betas\": (0.8, 0.95)}\n",
    "\n",
    "    else:\n",
    "        return {\"lr\": 0.001, \"betas\": (0.8, 0.95)}\n",
    "optimizer = Adam(per_param_callable)\n",
    "baseline = 0.\n",
    "\n",
    "\n",
    "for step in range(500):\n",
    "    # Synchronize gvs and param store. In the case of constrained parameters,\n",
    "    # the constrained value returned by pyro.param() is distinct from the\n",
    "    # unconstrianed value we optimize, so we need to regenerate the constrained value.\n",
    "    for var_name in guide_gvs.keys():\n",
    "        guide_gvs[var_name][0] = pyro.param(var_name + \"_est\")\n",
    "    loss = calc_score_and_backprob_async([env], n=1, guide_gvs=guide_gvs, optimizer=optimizer)\n",
    "    #loss = svi.step(observed_tree)\n",
    "    score_history.append(loss)\n",
    "\n",
    "    if (step % 5 == 0):\n",
    "        # Also generate a few example environments\n",
    "        # Generate a ground truth test environment\n",
    "        plt.figure().set_size_inches(20, 20)\n",
    "        for k in range(4):\n",
    "            plt.subplot(2, 2, k+1)\n",
    "            parse_tree = generate_unconditioned_parse_tree(initial_gvs=guide_gvs)\n",
    "            yaml_env = convert_tree_to_yaml_env(parse_tree)\n",
    "            try:\n",
    "                DrawYamlEnvironmentPlanar(yaml_env, base_environment_type=\"table_setting\", ax=plt.gca())\n",
    "            except:\n",
    "                print(\"Unhandled exception in drawing yaml env\")\n",
    "            draw_parse_tree(parse_tree, label_name=True, label_score=True)\n",
    "        if use_writer:\n",
    "            writer.add_figure(\"generated_envs\", plt.gcf(), step, close=True)\n",
    "\n",
    "    all_param_state = {name: pyro.param(name).detach().cpu().numpy().copy() for name in pyro.get_param_store().keys()}\n",
    "    if use_writer:\n",
    "        writer.add_scalar('loss', loss.item(), step)\n",
    "        for param_name in all_param_state.keys():\n",
    "            write_np_array(writer, param_name, all_param_state[param_name], step)\n",
    "    #print(\"active param names: \", active_param_names)\n",
    "    print(\"Place setting plate mean est: \", pyro.param(\"place_setting_plate_mean_est\"))\n",
    "    print(\"Place setting plate var est: \", pyro.param(\"place_setting_plate_var_est\"))\n",
    "print(\"Final loss: \", loss)\n",
    "print_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parse_tree = generate_hyperexpanded_parse_tree()\n",
    "#plt.figure().set_size_inches(20, 20)\n",
    "#draw_parse_tree(hyper_parse_tree, label_name=True, label_score=False)\n",
    "#plt.show()\n",
    "# Initialize the guide GVS as mean field\n",
    "guide_gvs = hyper_parse_tree.get_global_variable_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a ground truth test environment\n",
    "plt.figure().set_size_inches(20, 20)\n",
    "images = []\n",
    "for k in range(50):\n",
    "    plt.gca().clear()\n",
    "    trace = poutine.trace(generate_unconditioned_parse_tree).get_trace()\n",
    "    parse_tree = trace.nodes[\"_RETURN\"][\"value\"]        \n",
    "    score = trace.log_prob_sum()\n",
    "    yaml_env = convert_tree_to_yaml_env(parse_tree)\n",
    "    try:\n",
    "        DrawYamlEnvironmentPlanar(yaml_env, base_environment_type=\"table_setting\", ax=plt.gca())\n",
    "    except:\n",
    "        print(\"Unhandled exception in drawyamlenv\")\n",
    "    #draw_parse_tree(parse_tree, label_name=False, label_score=False)\n",
    "    plt.title(\"\")\n",
    "    plt.gca().axis('off')\n",
    "    images.append(dataset_utils.fig2data(plt.gcf()).copy())\n",
    "plt.gca().clear()\n",
    "for im in images:\n",
    "    plt.imshow(im, alpha=0.25)\n",
    "plt.gca().axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36_pyro] *",
   "language": "python",
   "name": "conda-env-py36_pyro-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
