{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from collections import OrderedDict\n",
    "import cv2\n",
    "import copy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import detectron2.utils.comm as comm\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.config import CfgNode as CN\n",
    "from detectron2.data import (\n",
    "    MetadataCatalog,\n",
    "    build_detection_test_loader,\n",
    "    build_detection_train_loader,\n",
    ")\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor, default_argument_parser, default_setup, launch\n",
    "from detectron2.evaluation import inference_on_dataset, COCOEvaluator\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.utils.events import EventStorage\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "import scene_generation.inverse_graphics.synthetic_scene_database_loader as data\n",
    "import scene_generation.inverse_graphics.roi_heads as roi_heads\n",
    "import scene_generation.inverse_graphics.meta_arch as meta_arch\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "DATA_ROOT = \"/home/gizatt/data/generated_cardboard_envs/\"\n",
    "DETECTRON_ROOT = \"/home/gizatt/tools/detectron2/\"\n",
    "\n",
    "%matplotlib inline\n",
    "def cv2_imshow(im):\n",
    "    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from scene_generation.inverse_graphics.synthetic_scene_database_loader import load_xencoco_json\n",
    "\n",
    "DatasetCatalog.clear()\n",
    "def load_dataset(d):\n",
    "    return load_xencoco_json(\n",
    "        os.path.join(DATA_ROOT, \"%s.json\" % (d)),\n",
    "        data_root=DATA_ROOT,\n",
    "        dataset_name=\"synthetic_%s\" % d)\n",
    "def load_real_dataset():\n",
    "    return detectron2.data.datasets.load_coco_json(\n",
    "        \"/home/gizatt/data/coco/cardboard_boxes_in_wild/coco.json\",\n",
    "        image_root=\"/home/gizatt/data/coco/cardboard_boxes_in_wild/images\",\n",
    "        dataset_name=\"prime_boxes_real\", extra_annotation_keys=None)\n",
    "for d in [\"train\", \"test\"]:\n",
    "    DatasetCatalog.register(\"synthetic_\" + d, lambda d=d: load_dataset(d))\n",
    "DatasetCatalog.register(\"prime_boxes_real\", load_real_dataset)\n",
    "synthetic_train_metadata = MetadataCatalog.get(\"synthetic_train\")\n",
    "real_prime_boxes_metadata = MetadataCatalog.get(\"prime_boxes_real\")\n",
    "real_prime_boxes_metadata.set(json_file=\"/home/gizatt/data/coco/cardboard_boxes_in_wild/coco.json\")\n",
    "print(\"Metadata train: \", synthetic_train_metadata)\n",
    "print(\"Metadata real: \", real_prime_boxes_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(os.path.join(DETECTRON_ROOT, \"configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "\n",
    "cfg.INPUT.MIN_SIZE_TRAIN = (480)\n",
    "cfg.INPUT.MIN_SIZE_TEST = (480)\n",
    "cfg.INPUT.DEPTH_FORMAT = 'L'\n",
    "cfg.DATALOADER.ASPECT_RATIO_GROUPING = False\n",
    "\n",
    "cfg.DATASETS.TRAIN = (\"synthetic_train\",)\n",
    "cfg.DATASETS.TEST = (\"synthetic_test\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.MODEL.META_ARCHITECTURE = \"GeneralizedRCNNWithDepthAndCalibration\"\n",
    "cfg.MODEL.DEPTH_PIXEL_MEAN = 1. # Totally made up\n",
    "cfg.MODEL.DEPTH_PIXEL_STD = 1.\n",
    "cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"  # initialize from model zoo\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # default\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class (prime box)\n",
    "cfg.MODEL.ROI_HEADS.NAME = \"XenRCNNROIHeads\"\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SHAPE_LOSS_WEIGHT = 1.0\n",
    "cfg.MODEL.ROI_HEADS.POSE_LOSS_WEIGHT = 1.0\n",
    "cfg.MODEL.ROI_HEADS.SHAPE_LOSS_NORM = 'l1'\n",
    "cfg.MODEL.ROI_HEADS.POSE_LOSS_NORM = 'l1'\n",
    "\n",
    "cfg.MODEL.MASK_ON = True\n",
    "cfg.MODEL.SHAPE_ON = True\n",
    "cfg.MODEL.POSE_ON = True\n",
    "cfg.MODEL.POSE_6DOF_ROT_ON = True # False -> Predict RPY as in 3DRCNN\n",
    "\n",
    "cfg.MODEL.ROI_SHARED_HEAD = CN()\n",
    "cfg.MODEL.ROI_SHARED_HEAD.POOLER_RESOLUTION = 14\n",
    "cfg.MODEL.ROI_SHARED_HEAD.POOLER_SAMPLING_RATIO = 2\n",
    "cfg.MODEL.ROI_SHARED_HEAD.POOLER_TYPE = \"ROIAlign\"\n",
    "\n",
    "cfg.MODEL.ROI_SHAPE_HEAD = CN()\n",
    "cfg.MODEL.ROI_SHAPE_HEAD.NAME = \"RCNNShapeHead\"\n",
    "cfg.MODEL.ROI_SHAPE_HEAD.NUM_CONV = 0\n",
    "cfg.MODEL.ROI_SHAPE_HEAD.CONV_DIM = 128 # formerly 3\n",
    "cfg.MODEL.ROI_SHAPE_HEAD.NUM_FC = 3\n",
    "cfg.MODEL.ROI_SHAPE_HEAD.FC_DIM = 256 # formerly 100\n",
    "cfg.MODEL.ROI_SHAPE_HEAD.NORM = \"\"\n",
    "cfg.MODEL.ROI_SHAPE_HEAD.NUM_SHAPE_PARAMS = 3\n",
    "cfg.MODEL.ROI_SHAPE_HEAD.NUM_SHAPE_BINS = 64\n",
    "cfg.MODEL.ROI_SHAPE_HEAD.SHAPE_BIN_RANGES = ((0., 0.5),\n",
    "                                             (0., 0.5),\n",
    "                                             (0., 0.5))\n",
    "\n",
    "cfg.MODEL.ROI_POSE_XYZ_HEAD = CN()\n",
    "cfg.MODEL.ROI_POSE_XYZ_HEAD.NAME = \"RCNNPoseXyzHead\"\n",
    "cfg.MODEL.ROI_POSE_XYZ_HEAD.NUM_CONV = 0\n",
    "cfg.MODEL.ROI_POSE_XYZ_HEAD.CONV_DIM = 128 # formerly 3\n",
    "cfg.MODEL.ROI_POSE_XYZ_HEAD.NUM_FC = 3\n",
    "cfg.MODEL.ROI_POSE_XYZ_HEAD.FC_DIM = 256 # formerly 100\n",
    "cfg.MODEL.ROI_POSE_XYZ_HEAD.NORM = \"\"\n",
    "cfg.MODEL.ROI_POSE_XYZ_HEAD.NUM_BINS = 64\n",
    "cfg.MODEL.ROI_POSE_XYZ_HEAD.XYZ_BIN_RANGES = ((-2., 2.),\n",
    "                                              (-2., 2.),\n",
    "                                              (0., 4.))\n",
    "\n",
    "cfg.MODEL.ROI_POSE_RPY_HEAD = CN()\n",
    "cfg.MODEL.ROI_POSE_RPY_HEAD.NAME = \"RCNNPoseRpyHead\"\n",
    "cfg.MODEL.ROI_POSE_RPY_HEAD.NUM_CONV = 0\n",
    "cfg.MODEL.ROI_POSE_RPY_HEAD.CONV_DIM = 128 # formerly 3\n",
    "cfg.MODEL.ROI_POSE_RPY_HEAD.NUM_FC = 3\n",
    "cfg.MODEL.ROI_POSE_RPY_HEAD.FC_DIM = 256 # formerly 100\n",
    "cfg.MODEL.ROI_POSE_RPY_HEAD.NORM = \"\"\n",
    "cfg.MODEL.ROI_POSE_RPY_HEAD.NUM_BINS = 64\n",
    "\n",
    "\n",
    "cfg.MODEL.ROI_POSE_6DOF_ROT_HEAD = CN()\n",
    "cfg.MODEL.ROI_POSE_6DOF_ROT_HEAD.NAME = \"RCNNPose6DOFRotHead\"\n",
    "cfg.MODEL.ROI_POSE_6DOF_ROT_HEAD.NUM_CONV = 0\n",
    "cfg.MODEL.ROI_POSE_6DOF_ROT_HEAD.CONV_DIM = 128 # formerly 3\n",
    "cfg.MODEL.ROI_POSE_6DOF_ROT_HEAD.NUM_FC = 3\n",
    "cfg.MODEL.ROI_POSE_6DOF_ROT_HEAD.FC_DIM = 256 # formerly 100\n",
    "cfg.MODEL.ROI_POSE_6DOF_ROT_HEAD.NORM = \"\"\n",
    "\n",
    "\n",
    "#cfg.DEVICE = 'cpu'\n",
    "#cfg.MODEL.DEVICE = 'cpu'\n",
    "#cfg.freeze()\n",
    "test_loader = build_detection_test_loader(cfg, dataset_name=\"synthetic_test\", mapper=data.XenRCNNMapper(cfg, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(cfg)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(DefaultTrainer):\n",
    "\n",
    "    @classmethod\n",
    "    def build_test_loader(cls, cfg, dataset_name):\n",
    "        return build_detection_test_loader(cfg, dataset_name, mapper=data.XenRCNNMapper(cfg, False))\n",
    "\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return build_detection_train_loader(cfg, mapper=data.XenRCNNMapper(cfg, True))\n",
    "\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name):\n",
    "        return COCOEvaluator(dataset_name, cfg, True, output_dir=cfg.OUTPUT_DIR)\n",
    "            \n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 50     # 300 iterations seems good enough for this toy dataset; you may need to train longer for a practical dataset\n",
    "cfg.OUTPUT_DIR = \"output/full_pose_with_6dof_rot_model_rgbd/\"\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg)\n",
    "trainer.resume_or_load(resume=True)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scene_generation.inverse_graphics.debug_draw import draw_shape_and_pose_predictions\n",
    "\n",
    "test_cfg = cfg.clone()  # cfg can be modified by model\n",
    "test_cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "test_cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model, default was 0.7\n",
    "test_cfg.DATASETS.TEST = (\"synthetic_test\", )\n",
    "\n",
    "test_model = build_model(test_cfg)\n",
    "test_model.eval()\n",
    "test_metadata = MetadataCatalog.get(test_cfg.DATASETS.TEST[0])\n",
    "\n",
    "checkpointer = DetectionCheckpointer(test_model)\n",
    "checkpointer.load(test_cfg.MODEL.WEIGHTS)\n",
    "\n",
    "height_to_show = 5\n",
    "plt.figure(dpi=100).set_size_inches(12, 12)\n",
    "test_loader_iterator = iter(test_loader)\n",
    "examples = [next(test_loader_iterator)[0] for k in range(height_to_show)]\n",
    "with torch.no_grad():  # https://github.com/sphinx-doc/sphinx/issues/4258\n",
    "    #inputs = {\"image\": image, \"height\": height, \"width\": width}\n",
    "    predictions = test_model(examples)\n",
    "    for k, pred in enumerate(predictions):\n",
    "        im_rgb, im_boxes = draw_shape_and_pose_predictions(examples[k], pred, test_metadata)\n",
    "        \n",
    "        \n",
    "        plt.subplot(height_to_show, 2, 2*k+1)\n",
    "        cv2_imshow(im_rgb)\n",
    "        plt.subplot(height_to_show, 2, 2*k+2)\n",
    "        cv2_imshow(im_boxes)\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_pyro",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
