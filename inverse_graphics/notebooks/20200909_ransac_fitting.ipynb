{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gizatt/miniconda3/envs/py36_pyro/lib/python3.6/site-packages/torchvision-0.6.0a0+fb562f5-py3.6-linux-x86_64.egg/torchvision/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "import cv2\n",
    "import copy\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import point_cloud_utils as pcu\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from skimage.transform import resize\n",
    "from skimage.color import rgb2gray\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import dense_correspondence_manipulation.utils.utils as utils\n",
    "\n",
    "import meshcat\n",
    "import meshcat.geometry as g\n",
    "\n",
    "import detectron2.utils.comm as comm\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.config import CfgNode as CN\n",
    "from detectron2.data import (\n",
    "    MetadataCatalog,\n",
    "    build_detection_test_loader,\n",
    "    build_detection_train_loader,\n",
    ")\n",
    "from detectron2.data.datasets import load_coco_json\n",
    "from detectron2.engine import DefaultTrainer, DefaultPredictor, default_argument_parser, default_setup, launch\n",
    "from detectron2.evaluation import inference_on_dataset, COCOEvaluator\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.utils.events import EventStorage\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "import scene_generation.inverse_graphics.synthetic_scene_database_loader as loader\n",
    "from scene_generation.inverse_graphics.synthetic_scene_database_loader import XenRCNNMapper\n",
    "import scene_generation.inverse_graphics.keypoint_mcmc.roi_heads as roi_heads\n",
    "from scene_generation.inverse_graphics.keypoint_mcmc.particle_filter_icp import *\n",
    "\n",
    "from pydrake.math import RigidTransform, RotationMatrix, RollPitchYaw\n",
    "from pydrake.solvers.mathematicalprogram import MathematicalProgram, Solve\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "\n",
    "DATA_ROOT = \"/home/gizatt/data/generated_cardboard_envs/\"\n",
    "DETECTRON_ROOT = \"/home/gizatt/tools/detectron2/\"\n",
    "\n",
    "\n",
    "class InstanceCloud():\n",
    "    def __init__(self, pts, colors, descriptors):\n",
    "        self.pts = pts\n",
    "        self.descriptors = descriptors\n",
    "        self.colors = colors\n",
    "    def get_augmented_pts(self, descriptor_factor=1.):\n",
    "        return np.vstack([self.pts, descriptor_factor*self.descriptors])\n",
    "    \n",
    "%matplotlib inline\n",
    "def cv2_imshow(im):\n",
    "    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "\n",
    "print(torchvision.__file__)\n",
    "\n",
    "load_dict = torch.load(\"run_on_all_records.pt\")\n",
    "all_instance_clouds_by_record = load_dict[\"all_instance_clouds_by_record\"]\n",
    "affinities_by_record = load_dict[\"affinities_by_record\"]\n",
    "clusters_by_record = load_dict[\"clusters_by_record\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7000/static/\n",
      "Downsampled scene from 31834 pts to 4861 pts.\n"
     ]
    }
   ],
   "source": [
    "# Load in data into numpy and o3d structures.\n",
    "\n",
    "import open3d as o3d\n",
    "import copy\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "clusters = []\n",
    "for c in list(clusters_by_record.values())[:10]:\n",
    "    clusters += c\n",
    "cluster = clusters[3]\n",
    "    \n",
    "vis = meshcat.Visualizer(zmq_url=\"tcp://127.0.0.1:6000\")[\"ransac_to_descriptors\"]\n",
    "vis.delete()\n",
    "\n",
    "def compute_unit_box_descriptors(pts, normals):\n",
    "    # Descriptor is the viridis color coding\n",
    "    # of the distance to the center of each pt's face.\n",
    "    face_local = np.abs(pts)*(normals == 0.0)*2\n",
    "    dist = np.linalg.norm(face_local, axis=0)/1.414\n",
    "    return torch.tensor(cm.get_cmap('viridis')(dist).astype(np.float32).T[:3, :])\n",
    "    \n",
    "# Make canonical box with descriptors\n",
    "N_model_pts = 1000\n",
    "model_pts, model_normals = make_unit_box_pts_and_normals(N=N_model_pts)\n",
    "model_colors = np.zeros((3, model_pts.shape[1]))\n",
    "model_colors[0, :] = 1.\n",
    "model_descriptors = compute_unit_box_descriptors(model_pts, model_normals).numpy()\n",
    "model_pts = np.dot(np.diag([0.5, 0.4, 0.3]), model_pts.numpy())\n",
    "model_normals = model_normals.numpy()\n",
    "\n",
    "scene_pts = cluster.pts.numpy()\n",
    "scene_descriptors = cluster.descriptors.numpy()\n",
    "\n",
    "def np_to_o3d(pts, colors, normals=None):\n",
    "    pts_o3d = o3d.geometry.PointCloud()\n",
    "    pts_o3d.points = o3d.utility.Vector3dVector(pts.copy().T)\n",
    "    pts_o3d.colors = o3d.utility.Vector3dVector(colors.copy().T)\n",
    "    if normals is not None:\n",
    "        pts_o3d.normals = o3d.utility.Vector3dVector(normals.copy().T)\n",
    "    else:\n",
    "        pts_o3d.estimate_normals()\n",
    "    return pts_o3d\n",
    "scene_pts_o3d = np_to_o3d(scene_pts, scene_descriptors)\n",
    "model_pts_o3d = np_to_o3d(model_pts, model_descriptors, model_normals)\n",
    "\n",
    "# Clean up the input data\n",
    "scene_pts_o3d, ind = scene_pts_o3d.remove_statistical_outlier(nb_neighbors=40,\n",
    "                                                              std_ratio=1.0)\n",
    "## And downsample some\n",
    "N_scene_pts_before = np.asarray(scene_pts_o3d.points).shape[0]\n",
    "scene_pts_o3d = scene_pts_o3d.voxel_down_sample(0.01)\n",
    "N_scene_pts_after = np.asarray(scene_pts_o3d.points).shape[0]\n",
    "print(\"Downsampled scene from %d pts to %d pts.\" % (N_scene_pts_before, N_scene_pts_after))\n",
    "# Pre-generate kd trees that might be in use\n",
    "scene_kdtree = o3d.geometry.KDTreeFlann(scene_pts_o3d)\n",
    "model_kdtree = o3d.geometry.KDTreeFlann(model_pts_o3d)\n",
    "\n",
    "vis[\"scene\"].set_object(\n",
    "    g.PointCloud(position=np.asarray(scene_pts_o3d.points).T,\n",
    "                 color=np.asarray(scene_pts_o3d.colors).T,\n",
    "                 size=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a23b3d818684f14b7325d97b26ee456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best fitness:  0.01501748611396832\n",
      "New best fitness:  0.1489405472125077\n",
      "New best fitness:  0.1553178358362477\n",
      "New best fitness:  0.18391277514914628\n",
      "New best fitness:  0.20571898786257972\n",
      "\n",
      "[[-8.91e-04  8.05e-04 -4.99e-04  3.13e-01]\n",
      " [ 4.36e-02 -1.07e-01  8.69e-02  7.42e-02]\n",
      " [ 2.70e-01  2.05e-01 -1.61e-01  2.83e-01]\n",
      " [ 0.00e+00  0.00e+00  0.00e+00  1.00e+00]] 0.20571898786257972\n"
     ]
    }
   ],
   "source": [
    "def select_ransac_inlier_set(N_corrs_to_select = 5):\n",
    "    # Pick N from the scene, and pick randomly from among the\n",
    "    # points in each of their neighborhood\n",
    "    scene_pt_ransac = []\n",
    "    model_pt_ransac = []\n",
    "    model_inds_for_masking = np.array(range(N_model_pts))\n",
    "    while len(scene_pt_ransac) < N_corrs_to_select:\n",
    "        scene_pt_ind = np.random.choice(N_scene_pts_after)\n",
    "        scene_pt = scene_pts_o3d.points[scene_pt_ind]\n",
    "        target_color = scene_pts_o3d.colors[scene_pt_ind]\n",
    "        model_pt_mask = np.linalg.norm(model_descriptors.T - target_color, axis=1) < 0.05\n",
    "        if np.sum(model_pt_mask) > 0:\n",
    "            model_pt_ind = np.random.choice(model_inds_for_masking[model_pt_mask])\n",
    "            scene_pt_ransac.append(scene_pt)\n",
    "            model_pt_ransac.append(model_pts[:, model_pt_ind])\n",
    "    model_pt_ransac = np.stack(model_pt_ransac)\n",
    "    scene_pt_ransac = np.stack(scene_pt_ransac)\n",
    "    return model_pt_ransac, scene_pt_ransac\n",
    "\n",
    "def fit_R_t_s(model_pt_ransac, scene_pt_ransac):\n",
    "    # Fit R, T, and scaling to the inlier set\n",
    "    prog = MathematicalProgram()\n",
    "    R = prog.NewContinuousVariables(3, 3, \"R\")\n",
    "    t = prog.NewContinuousVariables(3, \"t\")\n",
    "    s = prog.NewContinuousVariables(3, \"s\")\n",
    "    prog.AddBoundingBoxConstraint(np.ones(3)*0.1, np.ones(3)*2., s)\n",
    "    prog.AddBoundingBoxConstraint(np.ones(3)*-5., np.ones(3)*5., t)\n",
    "    prog.AddBoundingBoxConstraint(np.ones(9)*-1., np.ones(9)*1., R.flatten())\n",
    "    slack = prog.NewContinuousVariables(1, \"slack\")[0]\n",
    "    lhs = R.T.dot(R)\n",
    "    rhs = np.eye(3)\n",
    "    for u in range(3):\n",
    "        for v in range(3):\n",
    "            prog.AddConstraint(rhs[u, v] - lhs[u, v] >= -slack)\n",
    "            prog.AddConstraint(rhs[u, v] - lhs[u, v] <= slack)\n",
    "    #prog.AddConstraint(slack <= 0.1)\n",
    "    for model_pt, scene_pt in zip(model_pt_ransac, scene_pt_ransac):\n",
    "        err = scene_pt - (np.dot(R, np.diag(s).dot(model_pt)) + t)\n",
    "        prog.AddCost(np.sum(err**2.))\n",
    "    prog.AddCost(slack ** 2.)\n",
    "    prog.SetInitialGuess(R, np.eye(3))\n",
    "    result = Solve(prog)\n",
    "    if result.is_success():\n",
    "        R = result.GetSolution(R)\n",
    "        t = result.GetSolution(t)\n",
    "        s = result.GetSolution(s)\n",
    "        return True, R, t, s\n",
    "    else:\n",
    "        return False, None, None, None\n",
    "    \n",
    "def fit_Rs_t(model_pt_ransac, scene_pt_ransac):\n",
    "    # Fit R*s and T to the inlier set\n",
    "    prog = MathematicalProgram()\n",
    "    Rs = prog.NewContinuousVariables(3, 3, \"Rs\")\n",
    "    t = prog.NewContinuousVariables(3, \"t\")\n",
    "    prog.AddBoundingBoxConstraint(np.ones(3)*-5., np.ones(3)*5., t)\n",
    "    prog.AddBoundingBoxConstraint(np.ones(9)*-10., np.ones(9)*10., Rs.flatten())\n",
    "    for model_pt, scene_pt in zip(model_pt_ransac, scene_pt_ransac):\n",
    "        err = scene_pt - (Rs.dot(model_pt.T) + t)\n",
    "        prog.AddCost(np.sum(err**2.))\n",
    "    prog.SetInitialGuess(Rs, np.eye(3))\n",
    "    result = Solve(prog)\n",
    "    if result.is_success():\n",
    "        Rs = result.GetSolution(Rs)\n",
    "        t = result.GetSolution(t)\n",
    "        return True, Rs, t\n",
    "    else:\n",
    "        return False, None, None, None\n",
    "    \n",
    "best_fitness = 0.\n",
    "best_tf = np.eye(4)\n",
    "\n",
    "for k in tqdm(range(1000)):\n",
    "    model_pt_ransac, scene_pt_ransac = select_ransac_inlier_set(5)\n",
    "    \n",
    "    # This version doesn't always succeed (usually doesn't, actually)\n",
    "    # at getting the global min. Maybe the R^T R = I constraint is confusing\n",
    "    # the solver?\n",
    "    #success, R, t, s = fit_R_t_s(model_pt_ransac, scene_pt_ransac)\n",
    "    #Rs = np.dot(R, np.diag(s))\n",
    "    success, Rs, t = fit_Rs_t(model_pt_ransac, scene_pt_ransac)\n",
    "    Rs = Rs\n",
    "    U, S, V = np.linalg.svd(Rs)\n",
    "    R = np.dot(U, V.T)\n",
    "    # Find scale + skew SS s.t. R SS = Rs\n",
    "    SS = R.T.dot(Rs)\n",
    "    #Rs = np.dot(R, np.diag(s))\n",
    "    transformed_model_pts_ransac = (np.dot(Rs, model_pt_ransac.T).T + t).T\n",
    "    vis[\"model_pts_ransac\"].set_object(\n",
    "        g.PointCloud(position=transformed_model_pts_ransac,\n",
    "                     color=np.array([[1., 0., 0.]]*5).T,\n",
    "                     size=0.025))\n",
    "    vis[\"scene_pts_ransac\"].set_object(\n",
    "        g.PointCloud(position=scene_pt_ransac.T,\n",
    "                     color=np.array([[0., 0., 1.]]*5).T,\n",
    "                     size=0.025))\n",
    "    \n",
    "    if success:\n",
    "        # Apply transformation to model points and get inlier set\n",
    "        # by point distance\n",
    "        tf = np.eye(4)\n",
    "        tf[:3, :3] = Rs\n",
    "        tf[:3, 3] = t\n",
    "        results = o3d.registration.evaluate_registration(\n",
    "            source=model_pts_o3d,\n",
    "            target=scene_pts_o3d,\n",
    "            max_correspondence_distance=0.01,\n",
    "            transformation=tf)\n",
    "\n",
    "        transformed_model_pts = (tf[:3, :3].dot(model_pts).T + tf[:3, 3]).T\n",
    "        corrs = np.asarray(results.correspondence_set)\n",
    "        distances = np.linalg.norm(\n",
    "            transformed_model_pts[:, corrs[:, 0]] - \n",
    "            np.asarray(scene_pts_o3d.points).T[:, corrs[:, 1]], axis=0)\n",
    "        fitness = np.sum(distances < 0.1) / N_scene_pts_after\n",
    "        if fitness > best_fitness:\n",
    "            best_fitness = fitness\n",
    "            print(\"New best fitness: \", best_fitness)\n",
    "            best_tf = tf\n",
    "    else:\n",
    "        print(\"Fitting failed\")\n",
    "\n",
    "# Drawing\n",
    "transformed_model_pts = (best_tf[:3, :3].dot(model_pts).T + best_tf[:3, 3]).T\n",
    "print(best_tf, best_fitness)\n",
    "# Just draw\n",
    "vis[\"transformed_model\"].set_object(\n",
    "    g.PointCloud(position=transformed_model_pts,\n",
    "                 color=np.asarray(model_pts_o3d.colors).T,\n",
    "                 size=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Animate drawing correspondences with this scene cloud\n",
    "scene_offset = -np.mean(cluster.pts.numpy(), axis=1) + np.array([1., 0., 0.])\n",
    "vis[\"scene\"].set_object(\n",
    "    g.PointCloud(position=(cluster.pts.numpy().T + scene_offset).T,\n",
    "                 color=cluster.colors.numpy(),\n",
    "                 size=0.005))\n",
    "\n",
    "for x in np.linspace(0., 1., 100):\n",
    "    target_color = cm.get_cmap('viridis')(x)[:3]\n",
    "    model_inds = np.linalg.norm(model_descriptors.T - target_color, axis=1) < 0.05\n",
    "    scene_inds = np.linalg.norm(scene_descriptors.T - target_color, axis=1) < 0.05\n",
    "    vis[\"scene_highlight\"].set_object(\n",
    "        g.PointCloud(position=(scene_pts[:, scene_inds].T + scene_offset).T,\n",
    "                     color=scene_descriptors[:, scene_inds],\n",
    "                     size=0.02))\n",
    "    vis[\"model\"].set_object(\n",
    "    g.PointCloud(position=model_pts[:, model_inds],\n",
    "                 color=model_descriptors[:, model_inds],\n",
    "                 size=0.02))\n",
    "    time.sleep(0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
